{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIH Chest X-ray — Full Dataset Training (DenseNet vs ResNet)\n",
    "\n",
    "This notebook is adapted to the **official NIH Chest X-ray dataset structure**:\n",
    "- `Data_Entry_2017.csv` — labels\n",
    "- `train_val_list.txt` and `test_list.txt` — file splits\n",
    "- `images_001/ ... images_012/` — subfolders with PNG images\n",
    "\n",
    "### Workflow\n",
    "1. Load metadata and split files\n",
    "2. Build full filepaths from subfolders\n",
    "3. Encode multilabel classes\n",
    "4. Create efficient `tf.data` pipelines with augmentation\n",
    "5. Train **DenseNet121** and **ResNet50** with transfer learning (warmup + fine-tune)\n",
    "6. Use callbacks: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "7. Evaluate models with ROC AUC (macro, micro, per-class)\n",
    "8. Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Enable mixed precision if available\n",
    "try:\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"Mixed precision policy:\", mixed_precision.global_policy())\n",
    "except Exception as e:\n",
    "    print(\"Mixed precision not set:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = Path(\"/path/to/NIH-ChestXray\")   # <-- CHANGE THIS\n",
    "IMAGES_DIR = BASE_DIR / \"images\"\n",
    "CSV_FILE   = BASE_DIR / \"Data_Entry_2017.csv\"\n",
    "TRAINVAL_TXT = BASE_DIR / \"train_val_list.txt\"\n",
    "TEST_TXT     = BASE_DIR / \"test_list.txt\"\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "\n",
    "WARMUP_EPOCHS = 3\n",
    "FINETUNE_EPOCHS = 10\n",
    "INIT_LR = 1e-3\n",
    "FT_LR   = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file lists\n",
    "trainval_list = set(TRAINVAL_TXT.read_text().splitlines())\n",
    "test_list     = set(TEST_TXT.read_text().splitlines())\n",
    "print(\"Train/Val list:\", len(trainval_list))\n",
    "print(\"Test list:\", len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "df['Finding Labels'] = df['Finding Labels'].str.split('|')\n",
    "\n",
    "# Helper: find full path across subfolders\n",
    "def find_path(img_name):\n",
    "    for sub in IMAGES_DIR.iterdir():\n",
    "        candidate = sub / img_name\n",
    "        if candidate.exists():\n",
    "            return str(candidate)\n",
    "    return None\n",
    "\n",
    "df['filepath'] = df['Image Index'].apply(find_path)\n",
    "\n",
    "# Split according to txt lists\n",
    "trainval_df = df[df['Image Index'].isin(trainval_list)].reset_index(drop=True)\n",
    "test_df     = df[df['Image Index'].isin(test_list)].reset_index(drop=True)\n",
    "\n",
    "print(\"Train/Val:\", len(trainval_df), \" Test:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode multilabels\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(df['Finding Labels'])\n",
    "CLASSES = list(mlb.classes_)\n",
    "print(\"Classes:\", CLASSES)\n",
    "\n",
    "# Apply encoding\n",
    "Y_trainval = mlb.transform(trainval_df['Finding Labels'])\n",
    "Y_test     = mlb.transform(test_df['Finding Labels'])\n",
    "\n",
    "# Split train/val internally (90/10 stratified)\n",
    "train_df, val_df, Y_train, Y_val = train_test_split(\n",
    "    trainval_df, Y_trainval,\n",
    "    test_size=0.1, random_state=SEED,\n",
    "    stratify=trainval_df['Finding Labels'].apply(lambda x: str(x))\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Dataset pipeline\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def decode_resize(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "    img = img / 255.0\n",
    "    img = tf.image.grayscale_to_rgb(img)\n",
    "    return img, label\n",
    "\n",
    "def augment(img, label):\n",
    "    img = tf.image.random_brightness(img, 0.05)\n",
    "    img = tf.image.random_contrast(img, 0.95, 1.05)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    return img, label\n",
    "\n",
    "def make_ds(paths, labels, training=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(paths), seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(decode_resize, num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_ds(train_df['filepath'].values, Y_train, training=True)\n",
    "val_ds   = make_ds(val_df['filepath'].values,   Y_val, training=False)\n",
    "test_ds  = make_ds(test_df['filepath'].values,  Y_test, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model builders\n",
    "from tensorflow.keras.applications import DenseNet121, ResNet50\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def build_densenet(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=None):\n",
    "    if num_classes is None:\n",
    "        num_classes = len(CLASSES)\n",
    "    base = DenseNet121(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(num_classes, activation='sigmoid', dtype='float32')(x)\n",
    "    return Model(base.input, out)\n",
    "\n",
    "def build_resnet(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=None):\n",
    "    if num_classes is None:\n",
    "        num_classes = len(CLASSES)\n",
    "    base = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(num_classes, activation='sigmoid', dtype='float32')(x)\n",
    "    return Model(base.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=3, mode='max', restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.2, patience=2, mode='max', min_lr=1e-7),\n",
    "        tf.keras.callbacks.ModelCheckpoint(f\"best_{name}.h5\", monitor='val_auc', save_best_only=True, mode='max')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function (warmup + fine-tune)\n",
    "def compile_model(model, lr):\n",
    "    auc_roc = tf.keras.metrics.AUC(curve='ROC', multi_label=True, num_labels=len(CLASSES), name='auc')\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=[auc_roc])\n",
    "    return model\n",
    "\n",
    "def warmup_and_finetune(model_builder, name_prefix):\n",
    "    model = model_builder()\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "            layer.trainable = False\n",
    "    compile_model(model, lr=INIT_LR)\n",
    "    print(f\"\\n[Warmup] Training {name_prefix}...\")\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=WARMUP_EPOCHS, callbacks=get_callbacks(name_prefix))\n",
    "    for layer in model.layers[-50:]:\n",
    "        layer.trainable = True\n",
    "    compile_model(model, lr=FT_LR)\n",
    "    print(f\"\\n[Fine-tune] Training {name_prefix}...\")\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=FINETUNE_EPOCHS, callbacks=get_callbacks(name_prefix))\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "densenet_model, dn_hist = warmup_and_finetune(build_densenet, \"DenseNet\")\n",
    "resnet_model, rn_hist   = warmup_and_finetune(build_resnet, \"ResNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "def plot_history(histories, metric='auc'):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for name, hist in histories.items():\n",
    "        plt.plot(hist.history[metric], label=f\"{name} train\")\n",
    "        plt.plot(hist.history[f\"val_{metric}\"], label=f\"{name} val\")\n",
    "    plt.title(metric.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric.upper())\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history({'DenseNet': dn_hist, 'ResNet': rn_hist}, metric='auc')\n",
    "plot_history({'DenseNet': dn_hist, 'ResNet': rn_hist}, metric='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set\n",
    "def evaluate_model(model, dataset, y_true):\n",
    "    y_pred = model.predict(dataset)\n",
    "    macro = roc_auc_score(y_true, y_pred, average='macro')\n",
    "    micro = roc_auc_score(y_true, y_pred, average='micro')\n",
    "    per_class = dict(zip(CLASSES, roc_auc_score(y_true, y_pred, average=None)))\n",
    "    return macro, micro, per_class\n",
    "\n",
    "print(\"DenseNet Test Results:\", evaluate_model(densenet_model, test_ds, Y_test))\n",
    "print(\"ResNet Test Results:\", evaluate_model(resnet_model, test_ds, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import itertools\n",
    "\n",
    "def plot_per_class_roc(model1, model2, y_true, ds, name1=\"DenseNet\", name2=\"ResNet\"):\n",
    "    y_pred1 = model1.predict(ds)\n",
    "    y_pred2 = model2.predict(ds)\n",
    "\n",
    "    n_classes = len(CLASSES)\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(18, 24))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, cls in enumerate(CLASSES):\n",
    "        fpr1, tpr1, _ = roc_curve(y_true[:, i], y_pred1[:, i])\n",
    "        fpr2, tpr2, _ = roc_curve(y_true[:, i], y_pred2[:, i])\n",
    "        auc1 = auc(fpr1, tpr1)\n",
    "        auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.plot(fpr1, tpr1, label=f\"{name1} (AUC={auc1:.2f})\")\n",
    "        ax.plot(fpr2, tpr2, label=f\"{name2} (AUC={auc2:.2f})\")\n",
    "        ax.plot([0,1],[0,1],'k--')\n",
    "        ax.set_title(cls)\n",
    "        ax.set_xlabel('FPR')\n",
    "        ax.set_ylabel('TPR')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC per class on test set\n",
    "plot_per_class_roc(densenet_model, resnet_model, Y_test, test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
